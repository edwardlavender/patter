% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/pf_forward.R
\name{pf_forward}
\alias{pf_forward}
\title{PF: forward simulation}
\usage{
pf_forward(
  .obs,
  .dlist,
  .rpropose = pf_rpropose_kick,
  .dpropose = pf_dpropose,
  .likelihood = list(),
  .n = 100L,
  .sample = pf_sample_multinomial,
  .trial = pf_opt_trial(),
  .control = pf_opt_control(),
  .rerun = list(),
  .rerun_from = pf_opt_rerun_from(.rerun),
  .record = pf_opt_record(),
  .verbose = getOption("patter.verbose")
)
}
\arguments{
\item{.obs}{A \code{\link{data.table}} defining the timeline and associated observations, typically from \code{\link[=pf_setup_obs]{pf_setup_obs()}}.}

\item{.dlist}{A \code{named} list of data and parameters required propose samples and calculate likelihoods (see \code{\link[=pat_setup_data]{pat_setup_data()}}, \code{\link{pf_lik}} and \code{\link{pf_propose}}). At a minimum, this function requires \code{.dlist$spatial$bathy}. An \code{.dlist$spatial$origin} \code{\link{SpatRaster}} can be included to define the origin. Additional elements required by \code{.likelihood},\code{.rpropose} and \code{.dpropose} functions should be included (see below).}

\item{.rpropose, .dpropose}{Proposal functions (see \code{\link{pf_propose}}).
\itemize{
\item \code{.rpropose} is a function that proposes new locations for the individual, given previous locations. By default, this is a 'stochastic kick' function that simulates new locations by randomly kicking previous particles (see \code{\link[=pf_rpropose_kick]{pf_rpropose_kick()}} and Details).
\item \code{.dpropose} is a function that evaluates the probability density of movements between location pairs (see \code{\link{pf_dpropose}}). This is required for directed sampling (see Details).
}}

\item{.likelihood}{A named \code{list} of likelihood functions. These are used to calculate the likelihood of each dataset at proposal locations. See \code{\link{pf_lik}} for required arguments, convenience functions and advice.}

\item{.n, .sample}{Sampling arguments.
\itemize{
\item \code{.n} is an \code{integer} that defines the number of particle samples at each time step.
\item \code{.sample} is a function used to (re)-sample proposal locations (see \code{\link{pf_sample}}).
}}

\item{.trial}{A named \code{list} of tuning parameters for convergence, from \code{\link[=pf_opt_trial]{pf_opt_trial()}}.}

\item{.control}{A named \code{list} of control options, from \code{\link[=pf_opt_control]{pf_opt_control()}}.}

\item{.rerun, .rerun_from}{Rerun options. These options are used to restart the algorithm from an earlier time step in the case of a convergence failure.
\itemize{
\item \code{.rerun} is the named \code{list} of algorithm outputs from a previous rerun.
\item \code{.rerun_from} is an \code{integer} that defines the time step from which to rerun the algorithm.
}

Algorithm parameters should remain consistent on algorithm reruns.}

\item{.record}{A named \code{list} of output options, from \code{\link[=pf_opt_record]{pf_opt_record()}}.}

\item{.verbose}{User output control (see \code{\link{patter-progress}} for supported options).}
}
\value{
The function returns a \code{\linkS4class{pf_particles}} object. If \code{.return$sink} is specified, two directories, {.return$sink}/history/ and {.return$sink}/diagnostics, are also created that contain particle samples and diagnostics. Particle samples are labelled \verb{1.parquet, 2.parquet, ..., T.parquet}, where \code{T} is the number of time steps. Diagnostics are labelled \code{A-B-C}, where \code{A}, \code{B} and \code{C} are the number of manual restarts, internal reversions and time steps. Use \code{\link[=pf_forward_diagnostics]{pf_forward_diagnostics()}} to collate diagnostics.
}
\description{
This function runs the forward simulation, generating samples of the set of possible locations of an animal at each time point given the data up to that time point and a movement model.
}
\section{Overview}{
\code{\link[=pf_forward]{pf_forward()}} iterates over time steps, simulating location samples (termed 'particles') that are consistent with the preceding data and a movement model at each time step. At each time step, this process comprises four steps:
\enumerate{
\item A proposal step, in which we propose possible locations for the individual.
\item A likelihood step, in which we calculate the likelihood of the data given each proposal.
\item A weights step, in which we translate likelihoods into sampling weights.
\item A sampling step, in which we (re)sample valid proposal locations using the weights.
}

At the first time step, proposal locations are defined from a large number of 'quadrature points' across a \code{\link{SpatRaster}} that defines starting location(s), defined in \code{.dlist$spatial$origin} (\code{.dlist$spatial$bathy} is used if \code{.dlist$spatial$origin} is undefined). \code{NA}s/non \code{NA}s distinguish possible/impossible locations. For AC*PF algorithm implementations, grid cells beyond acoustic containers are masked. For *DCPF implementations, it is also desirable if you can, at least approximately, mask grid cells that are incompatible with the first depth observation. At the first time step, up to \code{1e6} locations ('quadrature points') are sampled from the \code{\link{SpatRaster}}. At each quadrature point, we evaluate likelihoods and calculate weights. \code{.n} starting locations (particles) are sampled from the set of quadrature points using the weights.

At subsequent time steps, proposal locations are generated via \code{.rpropose} which, by default, is a 'stochastic kick' function that 'kicks' previous particles at random into new locations (in line the restrictions imposed by a movement model). The benefit of this approach is that it is extremely fast, but in situations in which there are relatively few possible locations for an individual, the approach can work poorly because few kicked particles end up in valid locations. A \code{list} of likelihood functions is used to evaluate the likelihood of the data, given each proposal, and filter invalid proposals. During this time, we track how the number and diversity of proposal locations declines, as the data are revealed to be incompatible with selected proposals by successive likelihood functions (see Diagnostics). Likelihoods are translated into weights and \code{.n} valid proposals (particles) are resampled, with replacement, using the weights. If the number of unique, valid locations is <= \code{.trial_kick_crit}, this process is repeated up to \code{.trial_kick} times.

Following the stochastic-kick methodology, if the number of unique, valid locations is <= \code{.trial_sampler_crit}, directed sampling is initiated. For each unique, previous location, this methodology identifies the set of reachable cells, given a mobility parameter, and evaluates likelihoods and the probability density of movements into each reachable location (which are used to define sampling weights). \code{.n} locations are then directly sampled from the set of valid locations. This approach is expensive in terms of time (since it requires iteration over particles) and memory (since the complete set of valid locations is used for sampling). Particles can be processed in batches for improved speed, up to the limits imposed by available memory (see \code{.control}). While this approach is expensive, sampling from the set of valid locations facilitates convergence.

You can opt to use either \code{.rpropose} or directed sampling via the \code{.trial_} arguments. However, in general, it is advisable to permit the algorithm to chop-and-change between methods, depending on the number of valid proposals. This approach benefits from the speed benefits of stochastic kicks, where possible, as well as the improved convergence properties of directed sampling, where required.

Particle rejuvenation is another strategy that is sometimes used to facilitate convergence but this is not currently implemented.

At the end of each time step, if the number of unique, valid locations remains <= \code{.trial_revert_crit}, the algorithm can step backwards in time by \code{.trial_revert_steps} and try again. This reversion will be attempted up to \code{.trial_revert} times. After \code{.trial_revert} times, if the algorithm reaches a time step when there are fewer than \code{.trial_revert_crit} unique samples, it will produce a \code{\link{warning}}, but attempt to continue the simulation if possible. In the case of convergence failures, you can rerun the simulation from existing outputs, starting from an earlier time step, via \code{.rerun}. However, algorithm arguments should remain constant. On algorithm reversions and reruns, particle samplers are replaced but particle diagnostics are always retained.

The algorithm iterates over the time series, proposing and sampling particles as described above. Particle samples can be saved in memory or written to file, alongside particle diagnostics. If the function fails to convergence, a \code{\link{warning}} is returned alongside the outputs up to that time step. Otherwise, the function will continue to the end of the time series.
}

\section{Algorithms}{
This is highly flexible routine for the reconstruction of possible locations of an individual through time, given the data up to that time point. By modifying the likelihood functions, it is straightforward to implement the ACPF, DCPF and ACDCPF algorithms introduced by Lavender et al. (2023) for reconstructing movements using (a) acoustic time series, (b) archival time series and (c) acoustic and archival time series.
}

\section{Convergence and diagnostics}{
While \code{\link[=pf_forward]{pf_forward()}} tries hard to reconstruct a complete time series of location samples, algorithm convergence is not guaranteed. The algorithm may reach a dead-end---a time step at which there are no valid locations into which the algorithm can step. This may be due to data errors, incorrect assumptions, insufficient sampling effort or poor tuning parameter settings. To facilitate diagnosis of the immediate cause of convergence failures, during likelihood evaluations we keep track of 'particle diagnostics', i.e., the number of unique, valid locations before/after each likelihood evaluation alongside other statistics.
}

\examples{
#### Set up forward simulation
# Select example acoustic & archival datasets
acc <- dat_acoustics[individual_id == dat_acoustics$individual_id[1], ]
arc <- dat_archival[individual_id == acc$individual_id[1], ]
# Setup data list
dlist <- pat_setup_data(.acoustics = acc,
                        .archival = arc,
                        .moorings = dat_moorings,
                        .bathy = dat_gebco(),
                        .lonlat = FALSE)
# Setup AC* algorithm layers
dlist$algorithm$detection_overlaps <- acs_setup_detection_overlaps(dlist)
dlist$algorithm$detection_kernels  <- acs_setup_detection_kernels(dlist)
# Set up observations
obs <- pf_setup_obs(.dlist = dlist,
                    .trim = TRUE,
                    .step = "2 mins",
                    .mobility = 500,
                    .detection_range = 750)
# Subset observations for speed
obs <- obs[1:100L, ]

#### Example (1): Implement ACPF algorithm with default options
## Implement simulation
pf_lik_acpf <- list(acs_filter_land = acs_filter_land,
                    acs_filter_container = acs_filter_container,
                    pf_lik_ac = pf_lik_ac)
out_pff <- pf_forward(.obs = obs,
                      .dlist = dlist,
                      .likelihood = pf_lik_acpf,
                      .record = pf_opt_record(.save = TRUE))
## Examine output object
# The function returns a named list:
summary(out_pff)
# The `history` element contains a list of particle samples
head(out_pff$history[[1]])
head(out_pff$history[[2]])
# The `diagnostics` element contains data.table of particle diagnostics
head(out_pff$diagnostics, 20)
# `convergence` records convergence (TRUE/FALSE)
out_pff$convergence
# `time` records timings
out_pff$time

#### Example (2): Implement DCPF algorithm with default options
# Define shallow and depth limits
obs[, depth_shallow := depth - 20]
obs[, depth_deep := depth + 20]
# (optional) Define origin SpatRaster
origin <- dlist$spatial$bathy
origin <- terra::clamp(origin,
                       lower = obs$depth_shallow[1],
                       upper = obs$depth_deep[1])
dlist$spatial$origin <- origin
# Implement DCPF algorithm
pf_lik_dcpf <- list(pf_lik_dc = pf_lik_dc)
out_pff <- pf_forward(.obs = obs,
                      .dlist = dlist,
                      .likelihood = pf_lik_dcpf,
                      .record = pf_opt_record(.save = TRUE))

#### Example (3): Implement ACDCPF algorithm with default options
pf_lik_acdcpf <- list(pf_lik_dc = pf_lik_dc,
                      acs_filter_container = acs_filter_container,
                      pf_lik_ac = pf_lik_ac)
out_pff <- pf_forward(.obs = obs,
                      .dlist = dlist,
                      .likelihood = pf_lik_acdcpf,
                      .record = pf_opt_record(.save = TRUE))

#### Example (4): Customise movement model via `.rpropose` and `.dpropose`
# Pass arguments to the default models via ...
# > TO DO

# Write a new model with step lengths simulated from a lognormal distribution
hist(rlnorm(1e6L, meanlog = 5, sdlog = 0.25), xlim = c(0, 500))
pf_rpropose_lnorm <- function(.particles, .obs, .t, .dlist) {
  pf_rpropose_kick(.particles = .particles,
                   .obs = .obs,
                   .t = .t,
                   .dlist = .dlist,
                   .sim_length = function(.n) rlnorm(.n, meanlog = 5, sdlog = 0.25))
}
pf_dpropose_lnorm <- function(.particles, .obs, .t, .dist) {

}
# TO DO
# * Revise functions to make this easier

#### Example (5): Customise likelihood
# We can implement different algorithms by modifying the .likelihood list (above)
# We can also write custom likelihood functions
# As an example, we will imagine we have observed temperatures every two minutes
obs[, temp := rnorm(.N, 7)]
obs[, temp_cool := temp - 2]
obs[, temp_warm := temp + 2]
# We will also imagine we have hourly temperature data across the study area
# (e.g., from a hydrodynamic model)
obs[, hour := as.integer(cut(timestamp, "hour"))]
hours <- unique(obs$hour)
grid <- terra::setValues(dlist$spatial$bathy, NA)
nc   <- terra::ncell(grid)
temps <-
  hours |>
  lapply(function(hour) {
    vals <- rnorm(nc, 7)
    hydro <- terra::setValues(grid, vals)
    terra::mask(hydro, dlist$spatial$bathy)
  }) |>
  terra::rast()
names(temps) <- hours
terra::plot(temps)
dlist$spatial$temp <- temps
# Define the likelihood of the temp data given location proposals
pf_lik_temp <- function(.particles, .obs, .t, .dlist) {
  # Extract temps
  temp <- NULL
  locs <- terra::vect(cbind(.particles$x_now, .particles$y_now))
  .particles[, temp := terra::extract(x = .dlist$spatial$temp,
                                      y = locs,
                                      layer = .obs$hour[.t])$value]
  # Calculate temp likelihood
  # * We use a simple binary model for illustration
  # * Under this model, temperature observations that are not
  # * ... within a cool/warm limit are impossible
  .particles[, lik_temp := (temp >= .obs$temp_cool[.t] &
                              temp <= .obs$temp_warm[.t]) + 0, ]
  # Update likelihood & filter impossible locations
  lik <- NULL
  .particles[, lik := lik * lik_temp][lik > 0, ]
}
# Run simulation accounting for temperature data only
dlist$spatial$origin <- NULL
out_pff <- pf_forward(.obs = obs,
                      .dlist = dlist,
                      .likelihood = list(pf_lik_temp = pf_lik_temp),
                      .record = pf_opt_record(.save = TRUE))
# Run simulation accounting for multiple datasets
set.seed(1)
out_pff <- pf_forward(.obs = obs,
                      .dlist = dlist,
                      .likelihood = list(pf_lik_ac = pf_lik_ac,
                                         pf_lik_temp = pf_lik_temp),
                      .record = pf_opt_record(.save = TRUE))
# Note that the temperature likelihood (deliberately) has no influence here:
out_pff$diagnostics

#### Example (6): Customise (re)sampling
# Adjust the number of particles
out_pff <- pf_forward(.obs = obs,
                      .dlist = dlist,
                      .likelihood = pf_lik_acpf,
                      .n = 1000L,
                      .record = pf_opt_record(.save = TRUE))
nrow(out_pff$history[[1]])
# Use systematic resampling
# * This triggers directed sampling, so we boost sampler_batch_size for improved speed
out_pff <- pf_forward(.obs = obs,
                      .dlist = dlist,
                      .likelihood = pf_lik_acpf,
                      .sample = pf_sample_systematic,
                      .control = pf_opt_control(.sampler_batch_size = 100L),
                      .record = pf_opt_record(.save = TRUE))

#### Example (7): Control convergence via `.trial_` arguments
# See `vignette("c-demos", package = "patter")` for detailed examples

#### Example (8): Rerun the algorithm from an earlier time step
# This is only sensible in the case of a convergence failure,
# but for demonstration purposes:
out_pff_1 <- pf_forward(.obs = obs,
                      .dlist = dlist,
                      .likelihood = pf_lik_acpf,
                      .record = pf_opt_record(.save = TRUE))
out_pff_2 <- pf_forward(.obs = obs,
                        .dlist = dlist,
                        .likelihood = pf_lik_acpf,
                        .record = pf_opt_record(.save = TRUE),
                        .rerun = out_pff_1, .rerun_from = 5L)

#### Example (9): Adjust record options
# Use `sink` to write to particles to file (recommended)
pff_folder <- file.path(tempdir(), "forward")
dir.create(pff_folder)
out_pff <- pf_forward(.obs = obs,
                      .dlist = dlist,
                      .likelihood = pf_lik_acpf,
                      .record = pf_opt_record(.save = FALSE, .sink = pff_folder))
# > `save = FALSE` suppresses outputs in memory:
out_pff$history
out_pff$diagnostics
# > `sink` directs outputs to file:
list.files(pff_folder)
head(pf_files(file.path(pff_folder, "history")))
# > Check file size (MB)
pf_files_size(file.path(pff_folder, "history"))
# Use `cols` to restrict the output columns
cols <- c("timestep", "cell_now", "x_now", "y_now")
out_pff <- pf_forward(.obs = obs,
                      .dlist = dlist,
                      .likelihood = pf_lik_acpf,
                      .record = pf_opt_record(.save = FALSE,
                                              .sink = pff_folder,
                                              .cols = cols))
pf_files_size(file.path(pff_folder, "history"))
unlink(pff_folder, recursive = TRUE)

#### Example (10): Adjust standard `patter-progress` options
# Use a log.txt file
log.txt <- tempfile(fileext = ".txt")
out_pff <- pf_forward(.obs = obs,
                      .dlist = dlist,
                      .likelihood = pf_lik_acpf,
                      .record = pf_opt_record(.save = TRUE),
                      .verbose = log.txt)
readLines(log.txt)
unlink(log.txt)
# Suppress `.verbose`
out_pff <- pf_forward(.obs = obs,
                      .dlist = dlist,
                      .likelihood = pf_lik_acpf,
                      .record = pf_opt_record(.save = TRUE),
                      .verbose = FALSE)
# Suppress progress bar
pbo <- pbapply::pboptions(type = "n")
out_pff <- pf_forward(.obs = obs,
                      .dlist = dlist,
                      .likelihood = pf_lik_acpf,
                      .record = pf_opt_record(.save = TRUE))
pbapply::pboptions(pbo)
}
\seealso{
The forward filtering--backward sampling algorithm samples locations (particles) that represent the possible locations of an individual through time, accounting for all data and the individual's movement.
\itemize{
\item To set up data, use \code{\link[=pat_setup_data]{pat_setup_data()}}.
\item \code{\link[=pf_forward]{pf_forward()}} implements the forward filter:
\itemize{
\item To set up an observations timeline, use \code{\link[=pf_setup_obs]{pf_setup_obs()}}.
\item For proposal (movement) models, see \code{\link{pf_propose}}.
\item For likelihood functions, to evaluate the likelihood of the data at proposal locations, see \code{\link{pf_lik}}.
\item For sampling functions, to (re)sample plausible proposal locations, see \code{\link{pf_sample}}.
\item For tuning parameters, see \code{\link{pf_opt}}.
}
\item \code{\link[=pf_backward_*]{pf_backward_*()}} refines outputs from the forward filter:
\itemize{
\item \code{\link[=pf_backward_killer]{pf_backward_killer()}} removes dead-ends;
\item \code{\link[=pf_backward_sampler]{pf_backward_sampler()}} implements the backward sampler;
}
\item To reconstruct movement paths from particle samples, use \code{\link[=pf_path]{pf_path()}}.
\item To map emergent patterns of space use, use \code{\link[=pf_coord]{pf_coord()}} plus a \verb{map_*()} function, such as \code{\link[=map_pou]{map_pou()}}, \code{\link[=map_dens]{map_dens()}} and/or \code{\link{map_hr}}\verb{_()}.
\item For additional utilities, see supporting \verb{pf_*()} functions, such as \code{\link[=pf_files]{pf_files()}} and \code{\link[=pf_files_size]{pf_files_size()}}.
}
}
\author{
Edward Lavender
}
