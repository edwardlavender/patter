% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/pf_forward.R
\name{pf_forward}
\alias{pf_forward}
\title{PF: particle filter}
\usage{
pf_forward(
  .obs,
  .dlist,
  .rpropose = pf_rpropose_kick,
  .rargs = list(),
  .dpropose = pf_dpropose,
  .dargs = list(),
  .likelihood = list(),
  .n = 100L,
  .sample = pf_sample_systematic,
  .trial = pf_opt_trial(),
  .control = pf_opt_control(),
  .rerun = list(),
  .rerun_from = pf_opt_rerun_from(.rerun),
  .record = pf_opt_record(),
  .verbose = getOption("patter.verbose")
)
}
\arguments{
\item{.obs}{A \code{\link{data.table}} defining the timeline and associated observations, typically from \code{\link[=pf_setup_obs]{pf_setup_obs()}}.}

\item{.dlist}{A \code{named} list of data and parameters required propose locations and calculate likelihoods (see \code{\link[=pat_setup_data]{pat_setup_data()}}, \code{\link{pf_lik}} and \code{\link{pf_propose}}). This function requires:
\itemize{
\item \code{.dlist$spatial$bathy}
\item (optional) \code{.dlist$spatial$origin}, a \code{\link{SpatRaster}} used to define the origin. This may differ in geometry from \code{.dlist$spatial$bathy} but must have the same coordinate reference system.
\item \code{.dlist$pars$lonlat} (required by the default \code{.rpropose} and \code{.dpropose} arguments).
\item Any additional elements required by \code{.likelihood},\code{.rpropose} and \code{.dpropose} functions (see below).
}}

\item{.rpropose, .dpropose, .rargs, .dargs}{Proposal functions and associated argument lists (see \code{\link{pf_propose}}).
\itemize{
\item \code{.rpropose} is a function that proposes new locations for the individual, given previous locations. By default, this is a 'stochastic kick' function that simulates new locations by randomly kicking previous particles (see \code{\link[=pf_rpropose_kick]{pf_rpropose_kick()}} and Details).
\item \code{.dpropose} is a function that evaluates the probability density of movements between location pairs (see \code{\link[=pf_dpropose]{pf_dpropose()}}). This is required for directed sampling (see Details).
\item \code{.rargs} and \code{.dargs} are named \code{list}s of arguments passed to \code{.rpropose} and \code{.dpropose} respectively.
}}

\item{.likelihood}{A named \code{list} of likelihood functions. These are used to calculate the log-likelihood of each dataset at proposal locations. See \code{\link{pf_lik}} for required arguments, convenience functions and advice.}

\item{.n, .sample}{Sampling arguments.
\itemize{
\item \code{.n} is an \code{integer} that defines the number of particle samples at each time step.
\item \code{.sample} is a function used to (re)-sample proposal locations (see \code{\link{pf_sample}}).
}}

\item{.trial}{A named \code{list} of tuning parameters for convergence, from \code{\link[=pf_opt_trial]{pf_opt_trial()}}.}

\item{.control}{A named \code{list} of control options, from \code{\link[=pf_opt_control]{pf_opt_control()}}.}

\item{.rerun, .rerun_from}{Rerun options. These options are used to restart the algorithm from an earlier time step.
\itemize{
\item \code{.rerun} is the named \code{list} of algorithm outputs from a previous rerun.
\item \code{.rerun_from} is an \code{integer} that defines the time step from which to rerun the algorithm.
}}

\item{.record}{A named \code{list} of output options, from \code{\link[=pf_opt_record]{pf_opt_record()}}.}

\item{.verbose}{User output control (see \code{\link{patter-progress}} for supported options).}
}
\value{
The function returns a \code{\linkS4class{pf_particles}} object. If \code{.record$sink} is specified, particles are written to file in a series of parquet files (\verb{1.parquet, 2.parquet, ..., T.parquet}, where \code{T} is the number of time steps).
}
\description{
This function implements the particle filter ('forward simulation'). The filter iteratively samples possible locations (particles) of an animal at each time point given the data up to (and including) that time point and a movement model.
}
\section{Overview}{
\code{\link[=pf_forward]{pf_forward()}} iterates over time steps, simulating location samples (termed 'particles') that are consistent with the preceding data and a movement model at each time step. At each time step, this process comprises four steps:
\enumerate{
\item A proposal step, in which we propose possible locations for the individual.
\item A likelihood step, in which we evaluate the log-likelihood of the data given each proposal.
\item A weights step, in which we translate likelihoods into sampling weights.
\item A sampling step, in which we (re)sample valid proposal locations using the weights.
}

At the first time step, proposal locations are defined from a large number of 'quadrature points' across a \code{\link{SpatRaster}} that defines starting location(s), defined in \code{.dlist$spatial$origin} (\code{.dlist$spatial$bathy} is used if \code{.dlist$spatial$origin} is undefined). \code{NA}s/non \code{NA}s distinguish possible/impossible locations. For AC*PF algorithm implementations (i.e., implementations that incorporate acoustic data, see Algorithms, below), grid cells beyond acoustic containers are masked. For *DCPF implementations (i.e., implementations that incorporate depth data, see Algorithms, below), it is also desirable if you can, at least approximately, mask grid cells that are incompatible with the first depth observation. At the first time step, up to \code{1e6} locations ('quadrature points') are sampled from the \code{\link{SpatRaster}}. At each quadrature point, we evaluate log-likelihoods and calculate log-weights. \code{.n} starting locations (particles) are sampled, via \code{.sample}, from the set of quadrature points using the weights. If the effective sample size (ESS) of sampled locations is less than \code{.trial$trial_origin_crit}, a \code{\link{warning}} is given.

At subsequent time steps, proposal locations are generated via \code{.rpropose} which, by default, is a 'stochastic kick' function that 'kicks' previous particles at random into new locations (in line with the restrictions imposed by a movement model). This approach is relatively fast, but in situations in which there are relatively few possible locations for an individual, the approach can work poorly because few kicked particles end up in valid locations. A \code{list} of likelihood functions is used to evaluate the log-likelihood of the data, given each proposal, and optionally filter invalid proposals. Log-likelihoods are translated into weights for resampling (see below).

Following stochastic kicks, if the ESS is <= \code{.trial$trial_sampler_crit}, directed sampling is initiated. For the subset of (previous) locations for which stochastic kicks failed to generate valid samples, for each unique location, this methodology identifies the set of reachable cells, given a mobility parameter, and evaluates log-likelihoods and the log-probability density of movements into each reachable location (which are used to define sampling weights). This approach is expensive in terms of time (since it requires iteration over particles) and memory (since the complete set of valid locations is used for sampling). For this reason, it is currently only implemented for the subset of locations for which subsequent samples are lacking. Particles can be processed in batches for improved speed, up to the limits imposed by available memory (see \code{.control}). While this approach is expensive, sampling from the set of valid locations can facilitate convergence.

You can opt to use either \code{.rpropose} or directed sampling via the \code{.trial_} arguments to \code{\link[=pf_opt_trial]{pf_opt_trial()}}. By default, \code{\link[=pf_forward]{pf_forward()}} chops-and-changes between methods, depending on the ESS. This approach benefits from both the speed of stochastic kicks, where possible, and the improved convergence properties of directed sampling, where required.

Particle rejuvenation is another strategy that is sometimes used to facilitate convergence but this is not currently implemented.

At the end of each time step, the ESS of weighted particles is evaluated. If the ESS is below the critical value specified in \code{.trial$trial_resample_crit} and/or directed sampling is implemented, particles are (re)-sampled, via \code{.sample}.

The algorithm iterates over the time series, proposing, weighting and (re)sampling particles as described above. Particle samples can be saved in memory or written to file (with a speed penalty). If the function fails to convergence, a \code{\link{warning}} is returned alongside the outputs up to that time step. Otherwise, the function will continue to the end of the time series.
}

\section{Algorithms}{
This is highly flexible routine for the reconstruction of the possible locations of an individual through time, given the data up to that time point. By modifying the likelihood functions, it is straightforward to implement the ACPF, DCPF and ACDCPF algorithms introduced by Lavender et al. (2023) for reconstructing movements using (a) acoustic time series, (b) archival time series and (c) acoustic and archival time series. \code{\link[=pf_forward]{pf_forward()}} thus replaces (and enhances) the \href{https://edwardlavender.github.io/flapper/reference/ac.html}{\code{flapper::ac()}}, \href{https://edwardlavender.github.io/flapper/reference/dc.html}{\code{flapper::dc()}}, \href{https://edwardlavender.github.io/flapper/reference/acdc.html}{\code{flapper::acdc()}} and \href{https://edwardlavender.github.io/flapper/reference/pf.html}{\code{flapper::pf()}} functions.
}

\section{Convergence and diagnostics}{
Algorithm convergence is not guaranteed. The algorithm may reach a dead-end---a time step at which there are no valid locations into which the algorithm can step. This may be due to data errors, incorrect assumptions, insufficient sampling effort or poor tuning-parameter settings
}

\examples{
require(data.table)
require(dtplyr)
require(dplyr, warn.conflicts = FALSE)

#### Set up data list and observations timeline
# Set up data list(see `?pat_setup_data()`)
dlist <- dat_dlist()
# Add AC* algorithm layers
dlist$algorithm$detection_overlaps <- acs_setup_detection_overlaps(dlist)
dlist$algorithm$detection_kernels  <- acs_setup_detection_kernels(dlist)
# Set up observations (see `?pf_setup_obs()`)
obs <- dat_obs()

#### Define sub-models
# Define movement model
# * We will use the following defaults:
# * `?pf_rpropose_kick()`
# * `?pf_dpropose()`
# Define likelihood functions
# * We will use the following convenience functions:
pf_lik_acpf <- list(acs_filter_land = acs_filter_land,
                    acs_filter_container = acs_filter_container,
                    pf_lik_ac = pf_lik_ac)

#### Example (1): Implement ACPF algorithm with default options
## Run simulation
ssv()
out_pff <- pf_forward(.obs = obs,
                      .dlist = dlist,
                      .likelihood = pf_lik_acpf,
                      .record = pf_opt_record(.save = TRUE))
## Examine output object
# The function returns a named list:
summary(out_pff)
# `history` contains a list of particle samples
head(out_pff$history[[1]])
head(out_pff$history[[2]])
# `convergence` records convergence (TRUE/FALSE)
out_pff$convergence
# `time` records timings
out_pff$time

#### Example (2): Implement DCPF algorithm with default options
# Define shallow and depth errors
obs[, depth_shallow_eps := 20]
obs[, depth_deep_eps := 20]
# (optional) Define origin SpatRaster
shallow <- dlist$spatial$bathy - obs$depth_shallow_eps[1]
deep    <- dlist$spatial$bathy + obs$depth_deep_eps[1]
origin  <- (obs$depth[1] >= shallow) & (obs$depth[1] <= deep)
origin  <- terra::classify(origin, cbind(0, NA))
# Examine origin SpatRaster
terra::plot(origin)
dlist$spatial$bathy |>
  terra::mask(origin) |>
  as.data.frame(na.rm = TRUE) |>
  dplyr::select("bathy") |>
  range()
dlist$spatial$origin <- origin
# Implement DCPF algorithm
pf_lik_dcpf <- list(pf_lik_dc = pf_lik_dc)
ssv()
out_pff <- pf_forward(.obs = obs,
                      .dlist = dlist,
                      .likelihood = pf_lik_dcpf,
                      .record = pf_opt_record(.save = TRUE))

#### Example (3): Implement ACDCPF algorithm with default options
pf_lik_acdcpf <- list(pf_lik_dc = pf_lik_dc,
                      acs_filter_container = acs_filter_container,
                      pf_lik_ac = pf_lik_ac)
ssv()
out_pff <- pf_forward(.obs = obs,
                      .dlist = dlist,
                      .likelihood = pf_lik_acdcpf,
                      .record = pf_opt_record(.save = TRUE))

#### Example (4): Customise movement model via `.rpropose` and `.dpropose`
# Pass arguments to the default models via `.rargs` & `.dargs`
# * For `.rpropose` = `pf_rpropose_kick()`, `.rargs` get passed to
# * ... `.rkick` = `rkick()` > `.rstep` = `rstep()` >
# * ... `.rlen` = rlen(), `.rang` = rang()
# * For `.dpropose` = `pf_dpropose()`, `.dargs` gets passed to
# * ... `.dkick` = `dkick()` > `.dstep` = `dstep()` > `.dlen` = `dtruncgamma()`

# E.g., customise rlen() shape and scale parameters
hist(rlen(.n = 1e5L, .shape = 1, .scale = 100), xlim = c(0, 500))
out_pff <- pf_forward(.obs = obs,
                      .dlist = dlist,
                      .rpropose = pf_rpropose_kick,
                      .rargs = list(.shape = 1, .scale = 100),
                      .dpropose = pf_dpropose,
                      .dargs = list(.shape = 1, .scale = 100),
                      .likelihood = pf_lik_acdcpf,
                      .record = pf_opt_record(.save = TRUE))

# E.g., customise rlen() .mobility parameter
# > Restricted mobility leads to convergence failure
out_pff <- pf_forward(.obs = obs,
                      .dlist = dlist,
                      .rpropose = pf_rpropose_kick,
                      .rargs = list(.mobility = 100),
                      .dpropose = pf_dpropose,
                      .dargs = list(.mobility = 100),
                      .likelihood = pf_lik_acdcpf,
                      .record = pf_opt_record(.save = TRUE))
# > Pairwise steps are < .mobility + grid resolution/2
for (i in 2:length(out_pff$history)) {
  print(i)
  dist <- clen(out_pff$history[[i]][, .(x_past, y_past)],
               out_pff$history[[i]][, .(x_now, y_now)], .lonlat = FALSE)
  stopifnot(max(dist) < 100 + terra::res(dlist$spatial$bathy)[1] / 2)
}

## E.g. customise rlen() and dlen() models
# Write a new model with step lengths simulated from a lognormal distribution
hist(rlnorm(1e6L, meanlog = 5, sdlog = 0.25), xlim = c(0, 500))
out_pff <- pf_forward(.obs = obs,
                      .dlist = dlist,
                      .rpropose = pf_rpropose_kick,
                      .dpropose = pf_dpropose,
                      .rargs = list(.rlen = rlnorm, meanlog = 5, sdlog = 0.25),
                      .dargs = list(.dlen = dlnorm, meanlog = 5, sdlog = 0.25),
                      .likelihood = pf_lik_acdcpf,
                      .record = pf_opt_record(.save = TRUE))

#### Example (5): Customise likelihood
# We can implement different algorithms by modifying the .likelihood list (above)
# We can also write custom likelihood functions
# As an example, we will imagine we have observed temperatures every two minutes
obs[, temp := rnorm(.N, 7)]
obs[, temp_cool := temp - 2]
obs[, temp_warm := temp + 2]
# We will also imagine we have hourly temperature data across the study area
# (e.g., from a hydrodynamic model)
obs[, hour := as.integer(cut(timestamp, "hour"))]
hours <- unique(obs$hour)
grid <- terra::setValues(dlist$spatial$bathy, NA)
nc   <- terra::ncell(grid)
temps <-
  hours |>
  lapply(function(hour) {
    vals <- rnorm(nc, 7)
    hydro <- terra::setValues(grid, vals)
    terra::mask(hydro, dlist$spatial$bathy)
  }) |>
  terra::rast()
names(temps) <- hours
terra::plot(temps)
dlist$spatial$temp <- temps
# Define the likelihood of the temp data given location proposals
pf_lik_temp <- function(.particles, .obs, .t, .dlist, .drop) {
  # Extract temps
  temp <- NULL
  locs <- terra::vect(cbind(.particles$x_now, .particles$y_now))
  .particles[, temp := terra::extract(x = .dlist$spatial$temp,
                                      y = locs,
                                      layer = .obs$hour[.t])$value]
  # Calculate log-likelihood
  # * We use a simple binary model for illustration
  # * Under this model, temperature observations that are not
  # * ... within a cool/warm limit are impossible
  loglik_temp <- loglik <- NULL
  .particles[, loglik_temp := log((temp >= .obs$temp_cool[.t] &
                                     temp <= .obs$temp_warm[.t]) + 0), ]
  # Update log-likelihood
  .particles[, loglik := loglik + loglik_temp]
  # (optional) Filter impossible locations
  if (.drop && collapse::anyv(.particles$loglik, -Inf)) {
    .particles <- .particles[loglik > -Inf, ]
  }
  .particles
}
# Run simulation accounting for temperature data only
dlist$spatial$origin <- NULL
ssv()
out_pff <- pf_forward(.obs = obs,
                      .dlist = dlist,
                      .likelihood = list(pf_lik_temp = pf_lik_temp),
                      .record = pf_opt_record(.save = TRUE))
# Run simulation accounting for multiple datasets
ssv()
out_pff <- pf_forward(.obs = obs,
                      .dlist = dlist,
                      .likelihood = list(pf_lik_ac = pf_lik_ac,
                                         pf_lik_temp = pf_lik_temp),
                      .record = pf_opt_record(.save = TRUE))

#### Example (6): Customise (re)sampling
# Adjust the number of particles
ssv()
out_pff <- pf_forward(.obs = obs,
                      .dlist = dlist,
                      .likelihood = pf_lik_acpf,
                      .n = 1000L,
                      .record = pf_opt_record(.save = TRUE))
nrow(out_pff$history[[1]])

#### Example (7): Control convergence via `.trial_` arguments
# See `vignette("c-demos", package = "patter")` for detailed examples

#### Example (8): Rerun the algorithm from an earlier time step
# This is only sensible in the case of a convergence failure,
# but for demonstration purposes:
ssv()
out_pff_1 <- pf_forward(.obs = obs,
                      .dlist = dlist,
                      .likelihood = pf_lik_acpf,
                      .record = pf_opt_record(.save = TRUE))
ssv()
out_pff_2 <- pf_forward(.obs = obs,
                        .dlist = dlist,
                        .likelihood = pf_lik_acpf,
                        .record = pf_opt_record(.save = TRUE),
                        .rerun = out_pff_1, .rerun_from = 5L)

#### Example (9): Adjust record options
# Use `sink` to write to particles to file (slow)
pff_folder <- file.path(tempdir(), "forward")
dir.create(pff_folder)
ssv()
out_pff <- pf_forward(.obs = obs,
                      .dlist = dlist,
                      .likelihood = pf_lik_acpf,
                      .record = pf_opt_record(.save = FALSE, .sink = pff_folder))
# > `save = FALSE` does not save outputs in memory:
out_pff$history
# > `sink` directs outputs to file:
head(pf_files(file.path(pff_folder)))
# > Check file size (MB)
pf_files_size(file.path(pff_folder))
# Use `cols` to restrict the output columns
cols <- c("timestep", "cell_now", "x_now", "y_now")
ssv()
out_pff <- pf_forward(.obs = obs,
                      .dlist = dlist,
                      .likelihood = pf_lik_acpf,
                      .record = pf_opt_record(.save = FALSE,
                                              .sink = pff_folder,
                                              .cols = cols))
pf_files_size(file.path(pff_folder))
unlink(pff_folder, recursive = TRUE)

#### Example (10): Adjust standard `patter-progress` options
# Use a log.txt file (slow)
log.txt <- tempfile(fileext = ".txt")
ssv()
out_pff <- pf_forward(.obs = obs,
                      .dlist = dlist,
                      .likelihood = pf_lik_acpf,
                      .record = pf_opt_record(.save = TRUE),
                      .verbose = log.txt)
readLines(log.txt)
unlink(log.txt)
# Suppress `.verbose`
ssv()
out_pff <- pf_forward(.obs = obs,
                      .dlist = dlist,
                      .likelihood = pf_lik_acpf,
                      .record = pf_opt_record(.save = TRUE),
                      .verbose = FALSE)
# Suppress progress bar
pbo <- pbapply::pboptions(type = "n")
ssv()
out_pff <- pf_forward(.obs = obs,
                      .dlist = dlist,
                      .likelihood = pf_lik_acpf,
                      .record = pf_opt_record(.save = TRUE))
pbapply::pboptions(pbo)
}
\seealso{
The particle filter samples locations (particles) that represent the possible locations of an individual through time, accounting for the data and the individual's movement.
\itemize{
\item To set up data, use \code{\link[=pat_setup_data]{pat_setup_data()}}.
\item To implement the particle filter, use \code{\link[=pf_forward]{pf_forward()}}:
\itemize{
\item To set up an observations timeline, use \code{\link[=pf_setup_obs]{pf_setup_obs()}};
\item For proposal (movement) models, see \code{\link{pf_propose}};
\item For likelihood functions, to evaluate the likelihood of the data at proposal locations, see \code{\link{pf_lik}};
\item For sampling functions, to (re)sample plausible proposal locations, see \code{\link{pf_sample}};
\item For tuning parameters, see \code{\link{pf_opt}};
}
\item To map patterns of space use, use:
\itemize{
\item The backward smoother (TO DO);
\item \code{\link[=pf_coord]{pf_coord()}} to extract coordinates;
\item A \verb{map_*()} function, such as \code{\link[=map_pou]{map_pou()}}, \code{\link[=map_dens]{map_dens()}} and/or \code{\link{map_hr}}\verb{_()};
}
\item To reconstruct movement paths, use the backward sampler (TO DO).
\item For additional utilities, see supporting \verb{pf_*()} functions, such as \code{\link[=pf_files]{pf_files()}}, \code{\link[=pf_files_size]{pf_files_size()}}, \code{\link[=pf_plot_history]{pf_plot_history()}} and \code{\link[=pf_diag_summary]{pf_diag_summary()}}.
}
}
\author{
Edward Lavender
}
